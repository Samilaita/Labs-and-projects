{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NJCWxYEcPPwi"
      },
      "source": [
        "# Graph Learning\n",
        "\n",
        "## Lab 7: Graph Neural Networks"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YGZWvDRAPPwk"
      },
      "source": [
        "In this lab, you will learn to classify nodes using a graph neural network (GNN)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "tags": [],
        "id": "BW7rxbXNPPwk"
      },
      "source": [
        "## Import"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gQbX2pN6PPwk"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "from scipy import sparse\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install scikit-network"
      ],
      "metadata": {
        "id": "VjffJBjHk9gr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RzR-NqeDPPwl"
      },
      "outputs": [],
      "source": [
        "from sknetwork.classification import get_accuracy_score\n",
        "from sknetwork.data import load_netset\n",
        "from sknetwork.embedding import Spectral\n",
        "from sknetwork.gnn import GNNClassifier\n",
        "from sknetwork.utils import directed2undirected\n",
        "from IPython.display import SVG\n",
        "from sknetwork.visualization import visualize_graph\n",
        "from sknetwork.classification import DiffusionClassifier\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "\n",
        "from sklearn.manifold import TSNE"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_yHSTbWpPPwl"
      },
      "source": [
        "## Data"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NX90H1U-PPwl"
      },
      "source": [
        "We will work on the following datasets (see the [NetSet](https://netset.telecom-paris.fr/) collection for details):\n",
        "* Cora (directed graph + bipartite graph)\n",
        "* WikiVitals (directed graph + bipartite graph)\n",
        "\n",
        "Both datasets are graphs with node features (given by the bipartite graph) and ground-truth labels."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "iPmyW2uePPwl"
      },
      "outputs": [],
      "source": [
        "cora = load_netset('cora')\n",
        "wikivitals = load_netset('wikivitals')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Yjyhs17uPPwm"
      },
      "outputs": [],
      "source": [
        "def visualize_embedding(embedding, labels, size=(6,6)):\n",
        "    \"\"\"Visualize embedding in 2 dimensions using TSNE. \"\"\"\n",
        "    print(\"Computing TSNE...\")\n",
        "    tsne = TSNE(random_state=8).fit_transform(embedding)\n",
        "    fig, ax = plt.subplots(1, 1, figsize=size)\n",
        "    plt.scatter(tsne[:, 0], tsne[:, 1], c=labels, s=50, cmap='hsv')\n",
        "    plt.xticks([])\n",
        "    plt.yticks([])\n",
        "    plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "W-cb7QlcPPwm"
      },
      "source": [
        "## 1. Cora"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pVGnqLpjPPwm"
      },
      "source": [
        "We start with the Cora dataset. We check the embedding of the nodes before and after learning, and the impact of the GNN architecture on accuracy."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GYiedkziPPwm"
      },
      "outputs": [],
      "source": [
        "dataset = cora"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "w3k0a1C9PPwm"
      },
      "outputs": [],
      "source": [
        "adjacency = dataset.adjacency\n",
        "features = dataset.biadjacency\n",
        "labels_true = dataset.labels"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ob5dei4vPPwn"
      },
      "outputs": [],
      "source": [
        "# we use undirected graphs\n",
        "adjacency = directed2undirected(adjacency)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "SVG(visualize_graph(adjacency, width=800, height=800))"
      ],
      "metadata": {
        "id": "IPT6-3tNnXlE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kr9w7cAwPPwn"
      },
      "source": [
        "## To do\n",
        "\n",
        "Consider a GNN with a single hidden layer of dimension 16.\n",
        "\n",
        "* Run a single forward pass on the data, without learning.\n",
        "* Display the embedding provided by the hidden layer."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "oISI_7o8PPwn"
      },
      "outputs": [],
      "source": [
        "hidden_dim = 16"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Qtbd6j3IPPwn"
      },
      "outputs": [],
      "source": [
        "n_labels = len(set(labels_true))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "61fIzSTePPwn"
      },
      "outputs": [],
      "source": [
        "gnn = GNNClassifier(dims=[hidden_dim, n_labels], verbose=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7ZnRBWBUPPwn"
      },
      "outputs": [],
      "source": [
        "gnn"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "u21FFD4xPPwn"
      },
      "outputs": [],
      "source": [
        "output = gnn.forward(adjacency, features)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Sriy6ah-PPwn"
      },
      "outputs": [],
      "source": [
        "# hidden layer\n",
        "embedding = gnn.layers[0].embedding"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gkD8yfy5PPwn"
      },
      "outputs": [],
      "source": [
        "visualize_embedding(embedding, labels_true)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uS2xCwyXPPwn"
      },
      "source": [
        "## To do\n",
        "\n",
        "We now train the GNN.\n",
        "\n",
        "* Train the GNN with 50% / 50% train / test split.\n",
        "* Give the accuracy of the classification on the train and test sets.\n",
        "* Give the total number of parameters.\n",
        "* Display the embedding provided by the hidden layer."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "z4NphDtgPPwn"
      },
      "outputs": [],
      "source": [
        "# train / test split\n",
        "ratio_train = 0.5\n",
        "labels = labels_true.copy()\n",
        "mask_train = np.random.random(size=len(labels)) < ratio_train\n",
        "mask_test = ~mask_train\n",
        "labels[mask_test] = -1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dxI5sEk6PPwn"
      },
      "outputs": [],
      "source": [
        "gnn.fit(adjacency, features, labels)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UEKhcKEQPPwn"
      },
      "outputs": [],
      "source": [
        "labels_pred = gnn.predict()"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "accuracy_train = get_accuracy_score(labels_true[mask_train], labels_pred[mask_train])\n",
        "accuracy_test = get_accuracy_score(labels_true[mask_test], labels_pred[mask_test])\n",
        "print('Accuracy (train):', round(accuracy_train, 2))\n",
        "print('Accuracy (test):', round(accuracy_test, 2))\n",
        "print('Number of parameters :', (features.shape[0] * hidden_dim + hidden_dim))"
      ],
      "metadata": {
        "id": "QnZpZJJ3phh3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "embedding = gnn.layers[0].embedding\n",
        "visualize_embedding(embedding, labels_pred)"
      ],
      "metadata": {
        "id": "rPz7FjLlrVIb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xhPl00OiPPwo"
      },
      "source": [
        "## To do\n",
        "\n",
        "* Retrain the GNN with an empty graph.\n",
        "* Compare the accuracy of the classification with that of the previous model.\n",
        "* Comment the results. <br>What is the learning model?"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1zi0UJWRPPwo"
      },
      "outputs": [],
      "source": [
        "empty = sparse.csr_matrix(adjacency.shape)\n",
        "gnn_empty = GNNClassifier(dims=[hidden_dim, n_labels], verbose=True)\n",
        "gnn_empty.fit(empty, features, labels_true)\n",
        "labels_pred_empty = gnn_empty.predict()\n",
        "accuracy_train_empty = get_accuracy_score(labels_true[mask_train], labels_pred_empty[mask_train])\n",
        "accuracy_test_empty = get_accuracy_score(labels_true[mask_test], labels_pred_empty[mask_test])\n",
        "print('\\n--- Results with Empty Graph ---')\n",
        "print('Accuracy (train, empty graph):', round(accuracy_train_empty, 5))\n",
        "print('Accuracy (test, empty graph):', round(accuracy_test_empty, 5))\n",
        "print('\\n--- Comparison ---')\n",
        "print('Accuracy (train,  previous model):', round(accuracy_train, 5))\n",
        "print('Accuracy (test, previous model):', round(accuracy_test, 5))\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Comment :\n",
        "The results show that the model trained on the empty graph (i.e., without any edge information) significantly outperforms the standard GNN on both training and test accuracy. This suggests that the node features alone are highly informative, and the graph structure does not contribute positively to the classification task in this case.\n",
        "\n",
        "In fact, the GNN with one hidden layer (dim=16) might suffer from underfitting or oversmoothing, especially if the graph connectivity is not well aligned with class boundaries. This indicates that, for the Cora dataset, a simple MLP-like model using only node features can generalize better than a GNN relying on neighborhood aggregation."
      ],
      "metadata": {
        "id": "mFuoYOluyVNW"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TztHhGNsPPwo"
      },
      "source": [
        "## To do\n",
        "\n",
        "We now consider a hidden layer of dimension 32.\n",
        "\n",
        "* Retrain the GNN (with the graph).\n",
        "* Give the accuracy of the classification and the number of parameters.\n",
        "* Comment the results."
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "gnn_32 = GNNClassifier(dims=[32, n_labels], verbose=True)\n",
        "gnn_32.fit(adjacency, features, labels_true)\n",
        "labels_pred_32 = gnn_32.predict()\n",
        "accuracy_train_32 = get_accuracy_score(labels_true[mask_train], labels_pred_32[mask_train])\n",
        "accuracy_test_32 = get_accuracy_score(labels_true[mask_test], labels_pred_32[mask_test])\n",
        "\n",
        "input_dim = features.shape[1]\n",
        "hidden_dim = 32\n",
        "output_dim = n_labels\n",
        "\n",
        "n_params = (input_dim * hidden_dim + hidden_dim) + (hidden_dim * output_dim + output_dim)\n",
        "print(\"Number of parameters:\", n_params)\n",
        "print('--- GNN with Hidden Layer Dimension = 32 ---')\n",
        "print('Accuracy (train):', round(accuracy_train_32, 4))\n",
        "print('Accuracy (test):', round(accuracy_test_32, 4))\n",
        "print('Number of parameters:', n_params)\n"
      ],
      "metadata": {
        "id": "WbRKbL1HyvmB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sFpZFkdmPPwo"
      },
      "source": [
        "## To do\n",
        "\n",
        "Finally , we take 2 hidden layers, each of dimension 16.\n",
        "\n",
        "* Retrain the GNN.\n",
        "* Give the accuracy of the classification and the number of parameters.\n",
        "* Comment the results."
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "gnn_2layers = GNNClassifier(dims=[16, 16, n_labels], verbose=True)\n",
        "gnn_2layers.fit(adjacency, features, labels_true)\n",
        "labels_pred_2layers = gnn_2layers.predict()\n",
        "accuracy_train_2layers = get_accuracy_score(labels_true[mask_train], labels_pred_2layers[mask_train])\n",
        "accuracy_test_2layers = get_accuracy_score(labels_true[mask_test], labels_pred_2layers[mask_test])\n",
        "input_dim = features.shape[1]\n",
        "hidden_dim1 = 16\n",
        "hidden_dim2 = 16\n",
        "output_dim = n_labels\n",
        "\n",
        "n_params_2layers = (\n",
        "    (input_dim * hidden_dim1 + hidden_dim1) +\n",
        "    (hidden_dim1 * hidden_dim2 + hidden_dim2) +\n",
        "    (hidden_dim2 * output_dim + output_dim)\n",
        ")\n",
        "\n",
        "print('--- GNN with 2 Hidden Layers of Dimension 16 ---')\n",
        "print('Accuracy (train):', round(accuracy_train_2layers, 4))\n",
        "print('Accuracy (test):', round(accuracy_test_2layers, 4))\n",
        "print('Number of parameters:', n_params_2layers)\n"
      ],
      "metadata": {
        "id": "XMzaYauR04kE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "The results show that the GNN with two hidden layers of dimension 16 achieves good accuracy on both training and test sets, around 94-95%, with fewer parameters (23,335). However, increasing the hidden layer size to a single layer of dimension 32 significantly improves the accuracy, reaching almost perfect scores (around 99.8%) at the cost of roughly double the number of parameters (46,119). This suggests that a wider single hidden layer better captures the data patterns in this case, while deeper but narrower architectures may be less effective for this task."
      ],
      "metadata": {
        "id": "yr9H9caR13DL"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UfuBCdDzPPwo"
      },
      "source": [
        "## 2. Wikivitals"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VPIQGAroPPwo"
      },
      "source": [
        "We now focus on Wikivitals. We take the spectral embedding of the article-word bipartite graph as features."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "smIUtAdGPPwo"
      },
      "outputs": [],
      "source": [
        "dataset = wikivitals"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DhYg4R_-PPwo"
      },
      "outputs": [],
      "source": [
        "adjacency = dataset.adjacency\n",
        "biadjacency = dataset.biadjacency\n",
        "names = dataset.names\n",
        "labels_true = dataset.labels\n",
        "names_labels = dataset.names_labels"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_Q0uAP4MPPwo"
      },
      "outputs": [],
      "source": [
        "# we consider the graph as undirected\n",
        "adjacency = directed2undirected(adjacency)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "a-Zwu6EGPPwo"
      },
      "outputs": [],
      "source": [
        "# we use the spectral embedding of the bipartite graph as features\n",
        "spectral = Spectral(20)\n",
        "features = spectral.fit_transform(biadjacency)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PimOpQlZPPwo"
      },
      "source": [
        "## To do\n",
        "\n",
        "We consider a GNN with a single hidden layer of dimension 16.\n",
        "* Train the GNN with 50% / 50% train / test split.\n",
        "* Give the accuracy of the classification.\n",
        "* Display the confusion matrix of the test set.\n",
        "* Give for each label the 5 articles of the test set classified with the highest confidence."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bfZH6duNPPwo"
      },
      "outputs": [],
      "source": [
        "n_labels = len(set(labels_true))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KMueVQM9PPwo"
      },
      "outputs": [],
      "source": [
        "gnn = GNNClassifier(dims=[hidden_dim, n_labels], verbose=True)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "num_nodes = len(labels_true)\n",
        "indices = np.arange(num_nodes)\n",
        "np.random.shuffle(indices)\n",
        "split = num_nodes // 2\n",
        "mask_train = indices[:split]\n",
        "mask_test = indices[split:]\n",
        "gnn.fit(adjacency, features, labels_true)\n",
        "labels_pred = gnn.predict()\n",
        "accuracy_train = get_accuracy_score(labels_true[mask_train], labels_pred[mask_train])\n",
        "accuracy_test = get_accuracy_score(labels_true[mask_test], labels_pred[mask_test])\n",
        "print(f\"Accuracy (train): {accuracy_train:.4f}\")\n",
        "print(f\"Accuracy (test): {accuracy_test:.4f}\")"
      ],
      "metadata": {
        "id": "HJVYcIqx3cnA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "cm = confusion_matrix(labels_true[mask_test], labels_pred[mask_test], labels=range(n_labels))\n",
        "disp = ConfusionMatrixDisplay(confusion_matrix=cm)\n",
        "disp.plot(cmap=plt.cm.Blues)\n",
        "plt.title(\"Confusion Matrix - Test Set\")\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "XVbGRbvT32Ch"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "probs = gnn.predict_proba()\n",
        "for label in range(n_labels):\n",
        "    mask_label_test = (labels_pred[mask_test] == label)\n",
        "    test_indices_label = mask_test[mask_label_test]\n",
        "    conf_scores = probs[test_indices_label, label]\n",
        "    top5_idx = np.argsort(conf_scores)[-5:][::-1]\n",
        "    top5_nodes = test_indices_label[top5_idx]\n",
        "\n",
        "    print(f\"\\nLabel {label} ({names_labels[label]}) - Top 5 articles with highest confidence:\")\n",
        "    for node_id in top5_nodes:\n",
        "        print(f\"  {names[node_id]} (confidence: {conf_scores[np.where(test_indices_label == node_id)[0][0]]:.4f})\")\n"
      ],
      "metadata": {
        "id": "Qj6Ox6164DrN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WnM_4P1bPPw0"
      },
      "source": [
        "## To do\n",
        "\n",
        "Compare the results with those obtained with:\n",
        "* Heat diffusion on the graph.\n",
        "* Logistic regression on the features."
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# HeatDiffusion\n",
        "labels_train_masked = labels_true.copy()\n",
        "labels_train_masked[mask_test] = -1\n",
        "diffusion = DiffusionClassifier()\n",
        "diffusion.fit(adjacency, labels_train_masked)\n",
        "labels_pred_diffusion = diffusion.predict()\n",
        "accuracy_diffusion = get_accuracy_score(labels_true[mask_test], labels_pred_diffusion[mask_test])\n",
        "print(f\"Accuracy with Heat Diffusion: {accuracy_diffusion:.4f}\")\n",
        "\n",
        "# Logistic Regression on Spectral Features\n",
        "X_train_spec = features[mask_train]\n",
        "X_test_spec = features[mask_test]\n",
        "y_train = labels_true[mask_train]\n",
        "y_test = labels_true[mask_test]\n",
        "\n",
        "lr_spec = LogisticRegression(max_iter=1000)\n",
        "lr_spec.fit(X_train_spec, y_train)\n",
        "accuracy_spec = lr_spec.score(X_test_spec, y_test)\n",
        "print(f\"Accuracy with Spectral Features + Logistic Regression: {accuracy_spec:.4f}\")\n"
      ],
      "metadata": {
        "id": "I2FDDU2J5d6h"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "These results show a clear progression in model performance as you move from simpler to more complex approaches. Logistic regression on spectral features already outperforms heat diffusion combined with logistic regression, indicating that the spectral embeddings capture more informative representations of the nodes for classification. However, the GNN with a single hidden layer of dimension 16 achieves the highest test accuracy, demonstrating the benefit of leveraging both graph structure and node features jointly through learned message passing. This confirms that GNNs can better exploit complex relationships in the data than traditional methods based solely on fixed embeddings or diffusion processes."
      ],
      "metadata": {
        "id": "SMhYLnDu7D35"
      }
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.18"
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}